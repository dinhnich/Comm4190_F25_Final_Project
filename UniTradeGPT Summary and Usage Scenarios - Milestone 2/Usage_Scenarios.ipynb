{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda8cc66-1b65-4394-8bc3-5aad9dc29edc",
   "metadata": {},
   "source": [
    "## Trading\n",
    "**Short description** - Locating item listings to trade for through chat interaction\n",
    "\n",
    "\n",
    "**Narrative of scenario** - The user will engage in a chat conversation with UniTradeGPT and be prompted to describe the item they would like to trade for, including a description of it, its estimated value, and what (if anything) specific they are looking to trade it for. In the background, the LLM will be creating a listing from the item information in these chats (item name, estimated value, physical characteristics like color and size, etc) and identifying previous listings that accommodate the user’s desired parameters for the trade, like the type and value range of the other item.\n",
    "\n",
    "**Step by step break down of the interaction**\n",
    "In the application, the user opens the chat and selects the “Trade” button. In the background, the LLM would be sent a message to the effect of “The user would like assistance with trading an item.”\n",
    "The LLM will greet and prompt the user to describe the item they would like to trade for, including what it is and its physical descriptors like color, size, and weight.\n",
    "The user will offer a description of the item. In the background, the LLM will be creating the listing in the database and prompt for any information that is still needed about the item.\n",
    "The LLM will prompt the user to describe what, if anything in particular, the user is looking to trade their item for.\n",
    "The user will provide this information (e.g. item type, estimated value, color, etc.) In the background, the LLM is identifying previous listings that match these constraints.\n",
    "The LLM will provide a list of items that the user may be interested in trading their item for.\n",
    "\n",
    "**Data description**\n",
    "The LLM needs a database of item listings to access in order to search for recommendations.\n",
    "This includes things such as what each item is (e.g. guitar, textbook), their baseline physical descriptors (e.g. red, medium), and information about the user associated with them (e.g. affiliated with the University of Pennsylvania).\n",
    "As a result of the interaction, the LLM will create a new listing to be fulfilled.\n",
    "The listing will include information about this user’s item, as well as their parameters for items they are willing to trade for. For example, a user looking to trade may want to do so for a certain type of item (e.g. furniture, musical instrument). The LLM would be able to build this listing and update it as it gains information from the user.\n",
    "\n",
    "\n",
    "**Evaluation** - A check of how the recommendations output by the LLM align with the user’s parameters will confirm whether the application has successfully completed the scenario. This would include comparing any descriptors provided by the user of what items they are looking to trade for, and ensuring that the output matches. Possible complications/errors include the user not having preferences about the item to trade for, making the search difficult and possibly producing an output that contains listings the user may not find desirable or applicable. This could be avoided by ensuring that the LLM is provided some kind of baseline by the user as to what they are looking for or by defaulting to a certain kind of listing. For example, a user who wants to trade an item of furniture but informs the LLM that they do not have a preference on items to trade it for, may by default be recommended other kinds of furniture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc723b8-19b1-4ed2-926c-ad021ab2898e",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "**Short description** - Coordinate scheduling for a student who wants to buy an item.\n",
    "\n",
    "\n",
    "**Narrative of scenario** - When an item has been identified by the user for purchase, they will continue engaging in the chat conversation with UniTradeGPT and be prompted to provide their preference for pickup or delivery and their availability. In the background, the LLM will be retrieving information about the seller’s profile, including their schedule and parameters for pickup or delivery. The LLM will identify a day/time that works for both users and relay the relevant information to both. The LLM’s response can include a request for feedback as to the user’s satisfaction with the planned logistics.\n",
    "\n",
    "**Step by step break down of the interaction**\n",
    "Once an item has been found, either in the chat conversation or on the application, the user will be prompted by the LLM as to their preferences on how to acquire the item.\n",
    "The user will provide preference (e.g. pickup, delivery, meet at x location). In the background, the LLM will be retrieving the seller’s scheduling information and preferences.\n",
    "The LLM will determine logistics that work for both users, then provide the recommendation with a request for feedback as to the user’s satisfaction with it.\n",
    "The user will provide their assessment of the plan.\n",
    "If satisfied, the LLM will relay the information to the seller profile as a notification. If unsatisfied, the LLM will continue engaging with the (buying) user to coordinate a more preferable plan.\n",
    "\n",
    "**Data description**\n",
    "The LLM needs the selling users’ scheduling information and preferences.\n",
    "This includes things such as preference for pickup of delivery, locations, days and times that work, etc.\n",
    "As a result of the interaction, the LLM will use the buyer’s preferences to create a new pickup or delivery plan to be sent to the seller.\n",
    "The plan will include the time and location recommendation that was developed in the interaction with the buyer, and could be approved, amended, or rejected by the buyer.\n",
    "\n",
    "\n",
    "**Evaluation** - A check of how the logistics output by the LLM works with the scheduling and location parameters from both a) data from the seller’s profile and b) data from the chat interaction with the buyer will confirm whether the application has successfully completed the scenario. This would include comparing location and day/time availabiltiy with the final location recommendation and set day/time, ensuring that the output is compatible with those parameters. Possible complications/errors include the buyer and seller having incompatible schedules, meaning a logistics plan cannot be made that works for both users. In this case, the application can refer the users to a chat to work out the scheduling information further or send a notice to the seller of day/times that the buyer is available for, in order to see if the seller can make it work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227c04b-5846-4068-b292-8a5fb63db4c9",
   "metadata": {},
   "source": [
    "## Interior Design\n",
    "**Short Description:** Interior designing and finding pieces to furnish rooms/houses with the LLM. \n",
    "\n",
    "**Narrative of scenario:** The user will chat with the LLM and ask it to find pieces of furniture/decor and help with interior designing the space. The LLM will ask questions regarding overall aesthetics, what pieces of furniture the user already owns, pricepoints, how many people live in the house, space available, etc. The UniTradeGPT chatbot will then scan the database for items that might fit what the user is looking for and then present them to the user in both a list format with prices and dimensions clearly listed and in a generated image with all the furniture in configuration that gives the user a mockup of what everything will look like together. Then the user will give feedback and the chatbot will make any adjustments accordingly. When the user is satisfied they will indicate to the chatbot which items they want and the chatbot will coordinate with the seller. \n",
    "\n",
    "**Step by Step breakdown:**\n",
    "The user opens the chatbot feature and requests the “interior design” feature or help finding furniture/decorations. \n",
    "The LLM will ask questions to gather information on what the user wants. (eg. “What room do you want to furnish?”, “What aesthetic do you want, feel free to upload photos?”, “What is your budget?”, “What pieces do you already have?”, “How large is the space?”)\n",
    "The user will answer all the questions and upload any photos necessary. \n",
    "The LLM will then compile items that match the user’s general requests. There will be two outputs: a list with all the items and information regarding price, color, size, etc. and a generated image of a mockup of all the furniture in the space that the user is trying to furnish. \n",
    "The user will provide feedback of what they like and dislike. \n",
    "The LLM will return with other options. \n",
    "This continues until the user decides the stop or they feel satisfied. \n",
    "The user indicates which items they would like to purchase. \n",
    "The LLM coordinates the sale with the seller. \n",
    "\n",
    "**Data description:**\n",
    "LLM requires student information in order to verify they are a valid student and not a bot. \n",
    "LLM requires access to the seller/item database\n",
    "All sellers have to answer a series of questions about themselves and their preferences before uploading their item they want to sell\n",
    "All sellers will also have to upload detailed information about the item (eg. photo of the item, color, size, general price willing to sell for, condition, etc.)\n",
    "All this data will go into a cloud that the LLM can access\n",
    "User information\n",
    "As a result of the users responses for their preferences and what they are looking for, a “checklist” will be created for the LLM to follow. Since all of the user’s requests are unlikely to be fulfilled at the same time, the LLM will try to maximize the amount of checkboxes filled. \n",
    "\n",
    "**Evaluation:**\n",
    "To evaluate whether the “interior design” bot has successfully completed the scenario is to check how many items off the user’s checklist are completed as well as examine the generated image to ensure the room is fully furnished to the user’s liking. Success will be measured by how well the items fit into the user’s preferences and if the final design looks cohesive. If none of the the items fit the user’s original requests and they feel the need to manually search through the database, then that would be an issue. \n",
    "One of the larger complications that could occur is that none of the items in the database fit the user’s requests. If this is the case, then the LLM would re-prompt the user to see if they’d like to edit their original request or give the user alternatives (after informing the user that nothing fit their exact request). Another complication that could occur is that the user isn’t sure of what they want at all and provide very vague responses to the initial prompts. In that case, the LLM would prompt further and attempt to find what the user likes and dislikes through a series of tests. These tests would include showing stock images of furniture and having the user rate them on a scale of 1-10. If the request is inappropriate or illogical, the LLM will kindly re-ask the user or terminate the query if the user refuses to cooperate. \n",
    "\n",
    "Subleasing/renting out homes/items\n",
    "LLM can draft a contract\n",
    "LLM acts as a middleman between the two parties\n",
    "Seller or buyer can answer initial questions and LLM will respond directly on behalf of the seller or buyer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0a6c1-1aff-4a8c-80e4-ef6835049d2d",
   "metadata": {},
   "source": [
    "## Renting and Subletting Homes or Items\n",
    "\n",
    "**Short Description:** Organizing renting or subletting agreements between students with the LLM. \n",
    "\n",
    "**Narrative of scenario:** The user will first chat with the LLM to find a listing of either a living space or an item that they’d like to rent or sublease. Likely they’d be looking for a living accommodation for a short period of time (over breaks or summer), but this could also be used for renting large items (like cars) from other students. The LLM will then prompt the user for duration, price point, and specifics they’d like. Then UniTradeGPT will scan its database and provide a curated list of options for the user. The user can then scan through previews of options and choose one they’d like. Once they choose, the LLM will collect all necessary information from the user in order to make a contract. The person who originally owned the space or item will also have answered an initial set of questions. The AI chatbot will then act as the “middleman” between the two parties, drafting a contract and answering any simple questions on behalf of one of the two people. This is to streamline the process and protect both parties of people. Once everyone is satisfied with the contract, the LLM will then arrange any final agreements to be made. \n",
    "\n",
    "**Step by Step breakdown:**\n",
    "The user navigates to the “renting/sublet” tab on the interface and is greeted by the chatbot. \n",
    "The LLM prompts the user by asking what they are looking for. (eg. somewhere to live, car, generator, etc)\n",
    "The LLM then asks the user specific questions in order to narrow down the field. (eg. “When do you need this?”, “How long?”, “What is your budget?”, “Any specific features?”, etc.)\n",
    "The LLM will then search the database, providing the user with a curated list of ~5 options. These options will be in order of how well they fit the user’s request. \n",
    "If the user declines all options, the LLM will give more alternatives the user may like. \n",
    "Once the user decides they’d like to learn more about an option, it can ask questions to the LLM, and based on an initial questionnaire the “seller” filled out, it can answer more simple questions. \n",
    "Acting as a middleman between the two parties, the LLM will draft a contract, compromising between the two people. \n",
    "When both parties are satisfied with the contract, the LLM will organize any other agreements that are needed. \n",
    "\n",
    "**Data description:**\n",
    "LLM requires student information in order to verify they are a valid student and not a bot. \n",
    "LLM requires access to the home/item database\n",
    "All sellers have to answer a series of questions about themselves and their preferences before uploading their living space or item\n",
    "All sellers will also have to upload detailed information about the home/item (eg. extensive photos, general location (for privacy concerns), size, general price willing to rent for, condition, etc.)\n",
    "All this data will go into a secure cloud that only the LLM can access\n",
    "\n",
    "User information\n",
    "As a result of the users responses for their preferences and what they are looking for, a “checklist” will be created for the LLM to follow. Since all of the user’s requests are unlikely to be fulfilled at the same time, the LLM will try to maximize the amount of checkboxes filled. Some items will be prioritized. For example, location and budget are likely two of the most important factors so those requests will be filtered through first. \n",
    "\n",
    "**Evaluation:**\n",
    "To evaluate whether the application has successfully completed the scenario is to check how well the output lines up with the user’s request. If two of the most important factors, location and budget, aren’t being fulfilled, then there is an issue. Success will also be measured by whether or not the two parties are satisfied with the contract that the LLM has written up. If neither can come to a compromise, then the LLM failed the compatibility aspect of the matching people also by how they answered the initial questionnaire. \n",
    "Some complications that can occur is that there is nothing the LLM can find that is compatible with the user’s request. In that case, the LLM should re-prompt the user and see if they are willing to expand their original query. The user can then also open a standing request, which would mean that they would just receive a notification if a listing appears that matches their initial request. Another complication would be a difficult/non-compromising “buyer” or “seller”. In this case, there would be issues with drafting the contract and getting both parties to agree. Additionally, someone may ask for something inappropriate or illogical, and, in this case, the LLM would re-prompt the user or terminate the search if they refuse to cooperate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a7e78-cbd3-4340-bbd0-8184d020c7c9",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "**Short Description:** ‘Finding a specific item by giving specific details to the LLM’\n",
    "\n",
    "**Narrative of scenario:** ‘The user interacts with UniTradeGPT to find a specific type of desk within the secure, student-only marketplace, using natural language instead of manually applying filters. The user describes what they are looking for, including details such as dimensions, color, price range, and other desired qualities. UniTradeGPT interprets this input and searches the marketplace to compile a list of listings that best match the user’s preferences. It then presents the user with a curated list of matching items, each with direct links to the listings. In the background, the application automatically filters out any items that do not meet the given criteria while leaving unspecified qualities flexible. As the user provides additional details or changes their preferences, UniTradeGPT dynamically updates the results to reflect the new information, ensuring a more refined and personalized search experience.\n",
    "\n",
    "**Step by step break down of the interaction:**\n",
    "User opens chat and describes the target item in natural language (e.g., “white standing desk 48–55 inches, under $200, within 4 miles”).\n",
    "UniTradeGPT confirms/infers key constraints (category, dimensions, color, price, distance, condition) and parses them into structured filters.\n",
    "The app validates/normalizes inputs (unit conversion, color taxonomy, reasonable ranges).\n",
    "UniTradeGPT calls the backend search with the structured filters and community/radius context.\n",
    "Backend returns candidate listings (with attributes, status, links, distances, seller signals).\n",
    "UniTradeGPT ranks results (must-haves first, then nice-to-haves), adds short “why it matches” notes.\n",
    "User receives a curated list with direct links; unspecified attributes remain flexible.\n",
    "User refines constraints (e.g., “max $150” or “standing only”); UniTradeGPT re-filters and re-ranks.\n",
    " \n",
    "**Data description:**\n",
    "Needed for the app/LLM to engage and complete this scenario\n",
    "User identification data: Verified student email (to determine school/community), user ID, and distance radius from school (used for filtering listings).\n",
    "User query data: Natural language request describing desired item (e.g., “white standing desk under $200”).\n",
    "Parsed search parameters: LLM extracts structured details such as category (e.g., furniture > desk), dimensions (width/height), color, material, price range, condition, and distance range.\n",
    "Marketplace listing data: Item title, description, category, price, condition, dimensions, color, material, location (coarse or community-level), seller verification status, and photo URLs.\n",
    "Supporting data:\n",
    "Knowledge of synonyms and taxonomies (e.g., “off-white” → white).\n",
    "Conversion data (e.g., inches to cm).\n",
    "Distance calculations (listing-to-user proximity).\n",
    "\n",
    "\n",
    "How data is provided to the LLM:\n",
    "User’s query text is input directly to the LLM.\n",
    "LLM outputs structured JSON constraints to backend search functions (e.g., search_listings).\n",
    "Backend returns matching listings with structured metadata for the LLM to rank and present.\n",
    "Created as a result of the interaction\n",
    "Structured query representation: A JSON record of parsed filters and constraints (e.g., price ≤ $200, color = white).\n",
    "Search result dataset: Ranked list of matching listings with IDs, links, match scores, and key attributes.\n",
    "Query refinement history: Log of how filters or preferences change during the conversation.\n",
    "Inferred user preferences: Aggregated trends such as typical price range, color preferences, or item categories (optional, with consent).\n",
    "Interaction data: Conversation transcript (PII minimized), tool-call logs, and engagement metrics (e.g., clicks, saves).\n",
    "Compliance and audit records: Verification of community access, search logs, and content safety flags for monitoring or review.\n",
    "\n",
    "\n",
    "**Evaluation**\n",
    "To evaluate whether the filtering feature works successfully, we will test if UniTradeGPT can accurately return items that match the user’s description. This includes checking whether the listings shown meet all the user’s specified qualities such as size, color, price, and condition. The success of the scenario will be measured by how relevant and accurate the search results are, how quickly they are returned, and whether the user feels the results reflect their request without needing to manually adjust filters. \n",
    "Possible complications include the user giving vague or conflicting input (for example, “cheap large desk”), which could make it hard for the LLM to know what to prioritize. Unexpected or adversarial input might also appear, such as nonsensical or inappropriate descriptions, which the system should detect and handle safely by asking for clarification or refusing the query. Errors could occur if item listings are missing key information (like dimensions), if units are mixed up, or if items are sold or outdated but still appear in results. To prevent these, the app should include validation checks, clear error messages, and safe fallback responses that prompt the user to refine or simplify their request.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ca2a9-1e28-4add-8db3-3da73b08926e",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "**Short Description:** ‘“Side-by-side listing comparison with an LLM-guided recommendation.’\n",
    "\n",
    "**Narrative of scenario:** The user asks UniTradeGPT to compare two marketplace listings (or asks for “the best between A and B” with certain preferences like price, durability, or size). UniTradeGPT collects the specs, price, condition, seller ratings, and any available user reviews for both items. It aligns attributes in a side-by-side view, highlights where one listing is stronger, calls out trade-offs (e.g., “cheaper but older,” “newer but farther”), and ends with a brief recommendation tailored to the user’s stated priorities. If the user adjusts preferences (e.g., “price matters most, not brand”), the comparison updates instantly.\n",
    "\n",
    "**Step by step break down of the interaction:**\n",
    "User asks to compare two listings (provides links/IDs) and optionally states priorities (e.g., price > condition > distance).\n",
    "UniTradeGPT fetches normalized details for both items: specs, price, condition/age, dimensions, distance, seller rating, review summary, photos, status.\n",
    "Missing or inconsistent fields are flagged (e.g., unknown dimensions); UniTradeGPT may ask a brief clarifying question or mark as “unknown.”\n",
    "UniTradeGPT constructs a side-by-side comparison matrix (attribute → A vs. B), highlighting wins, ties, and trade-offs.\n",
    "Based on the user’s priority list, UniTradeGPT provides a short recommendation (e.g., “Pick A for value; pick B for better condition and warranty”).\n",
    "User adjusts priorities (“distance first” or “budget cap changed”); UniTradeGPT re-scores, updates highlights, and revises the recommendation.\n",
    "User opens chosen listing, saves it, or asks to compare a new pair; optional feedback recorded.\n",
    "\n",
    "**Data description – what data is:**\n",
    "Needed for the app/LLM to engage and complete this scenario\n",
    "User input: Two listing links/IDs (or request to pick top two), plus preferences/priorities (e.g., price > condition > distance).\n",
    "Context (non-PII identifiers): Community/region and search radius (derived from user profile), used to compute distance.\n",
    "Listing metadata (from backend services, provided to LLM via tool calls):\n",
    "Title, brand/model, category/subcategory\n",
    "Price, currency, negotiable flag\n",
    "Condition, age, included accessories/warranty\n",
    "Dimensions/weight/material/color\n",
    "Location (coarse), computed distance to user\n",
    "Photos (URLs), posting recency/status (active/sold)\n",
    "Seller & reputation signals (from backend): Seller verification flag, rating average/count, basic review summaries (no raw PII).\n",
    "Normalization/taxonomy helpers (services, not prompts): Units (in↔cm), color/material mapping, attribute synonyms.\n",
    "How provided to the LLM: The UI sends the user’s request; the LLM issues tool calls to fetch normalized, structured JSON for both listings and reviews; the LLM only receives needed fields and internal IDs (no student emails/phone numbers).\n",
    "Created as a result of the interaction\n",
    "Comparison matrix: Attribute-by-attribute table (A vs. B) with highlights (wins/losses/ties) and notes on unknowns.\n",
    "Recommendation summary: A short, ranked rationale aligned to the user’s stated priorities.\n",
    "Preference snapshot (optional, with consent): Current priority weights and any inferred preferences (e.g., “often favors price over condition”).\n",
    "Interaction log (PII-minimized): Prompt, tool-call metadata, chosen recommendation, and user feedback (thumbs up/down).\n",
    "Quality flags: Missing field markers, suspected stale listings, or inconsistent data for follow-up curation.\n",
    "\n",
    "**Evaluation**\n",
    "To determine whether the comparison feature works successfully, we will assess if UniTradeGPT accurately displays the correct details for both listings, clearly highlights the key differences, and provides a recommendation that reflects the user’s stated priorities. Success will be measured by the accuracy of information shown (no incorrect specs or missing data), the clarity and readability of the comparison (easy for users to scan and understand), and the responsiveness of the system when users adjust their preferences. The ultimate indicator of success is that users feel the comparison helps them make a faster, more confident decision than manually reviewing separate listings.\n",
    "Possible complications include missing or inconsistent data. In those cases, the system should clearly indicate that information is unavailable and, where possible, suggest follow-up actions like prompting the seller for details. Ambiguous preferences may also cause confusion and the LLM should ask clarifying questions or apply a sensible default, such as prioritizing price first. Other issues, like stale or broken listings, should be detected before display, with the user notified or alternative listings suggested. The system should also be designed to reject inappropriate or unsafe input and protect personal data by using internal identifiers only. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
